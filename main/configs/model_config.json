{
    "context_len": 512,
    "d_model": 512,
    "n_heads": 8,
    "n_blocks": 6,
    "vocab_size": 10000,
    "pos_emb_dropout_p": 0.1,
    "learned": false,
    "ntk_rope_scaling": false,
    "dyn_scaling": false,
    "attn_type": "mhsa",
    "n_groups": null,
    "top_k_sparsev": null,
    "p_threshold": null,
    "p_threshold_steps_fraction": null,
    "flash_attn": true,
    "pos_emb_type": "rope",
    "mixed_precision": false,
    "flash_attn_dtype": "float16",
    "compile": true,
    "parallel": "ddp",
    "fsdp_wrap_policy": "auto"
}